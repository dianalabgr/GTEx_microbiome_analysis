#Read the file with the names of the samples that we will use 
with open('samples.txt') as fh:
	samples = [line.strip() for line in fh]
	print(samples)

#rule for making all outputs
rule rule_all:
	input:
		expand("humann_uniref90_microbialReads_bypass2/{sample}_genefamilies.tsv",sample=samples),
		expand("humann_uniref90_microbialReads_bypass2/{sample}_pathabundance.tsv",sample=samples),
		expand("humann_uniref90_microbialReads_bypass2/{sample}_pathcoverage.tsv",sample=samples),
		expand("fastq_files/{sample}.fastq",sample=samples)
	
	
#rule run hummann against uniref90 
rule humann:
	input: 
		R1="../bowtie_folder/bowtie_fastq/{sample}_1.fastq.gz",
		R2="../bowtie_folder/bowtie_fastq/{sample}_2.fastq.gz"
	output:
		fastq="fastq_files/{sample}.fastq",
		gene="humann_uniref90_microbialReads_bypass2/{sample}_genefamilies.tsv",
		pathabundance="humann_uniref90_microbialReads_bypass2/{sample}_pathabundance.tsv",
		pathcoverage="humann_uniref90_microbialReads_bypass2/{sample}_pathcoverage.tsv"
	threads : 5
	shell: 
		r"""
		zcat {input.R1} {input.R2} > {output.fastq}
		humann --input  {output.fastq} -v --output ./humann_uniref90_microbialReads_bypass2/ --bypass-nucleotide-index --bypass-nucleotide-search --threads {threads}  --output-format tsv --protein-database /mnt/raid1/humann/databases/uniref/ 
		"""

#Check https://github.com/biobakery/humann?tab=readme-ov-file#markdown-header-custom-reference-database-annotations
#To download the full UniRef90 database (20.7GB, recommended): 
# humann_databases --download uniref uniref90_diamond $INSTALL_LOCATION





